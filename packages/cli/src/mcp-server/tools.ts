// generated by polka.codes

import * as path from 'node:path'
// Memory imports
import { detectProjectScope, getGlobalConfigPath, loadConfigAtPath, MemoryManager, SQLiteMemoryStore } from '@polka-codes/cli-shared'
import type { Logger, WorkflowFn } from '@polka-codes/core'
import { DEFAULT_MEMORY_CONFIG } from '@polka-codes/core'
import { z } from 'zod'
import { commit } from '../api'
import { runWorkflow } from '../runWorkflow'
import type { CliToolRegistry } from '../workflow-tools'
import { codeWorkflow } from '../workflows/code.workflow'
import { fixWorkflow } from '../workflows/fix.workflow'
import { planWorkflow } from '../workflows/plan.workflow'
import { reviewWorkflow } from '../workflows/review.workflow'
import type { BaseWorkflowInput } from '../workflows/workflow.utils'
import type { DefaultProviderConfig, McpServerTool, McpServerToolContext, ProviderOverride } from './types'

/**
 * Get memory store instance for MCP server tools
 * Lazy-loads memory store on first access
 */
let memoryStoreCache: { store: MemoryManager; close: () => void } | null = null

async function getMemoryStore(logger: Logger): Promise<{ store: MemoryManager; close: () => void } | null> {
  if (memoryStoreCache) {
    return memoryStoreCache
  }

  try {
    const globalConfigPath = getGlobalConfigPath()
    const config = (await loadConfigAtPath(globalConfigPath)) as { memory?: { enabled: boolean; type: string; path?: string } } | null
    const memoryConfig = config?.memory || DEFAULT_MEMORY_CONFIG

    if (!memoryConfig.enabled || memoryConfig.type === 'memory') {
      return null
    }

    const cwd = process.cwd()
    const scope = detectProjectScope(cwd)
    const dbPath = memoryConfig.path || DEFAULT_MEMORY_CONFIG.path
    const resolvedDbPath = path.resolve(cwd, dbPath)

    const sqliteStore = new SQLiteMemoryStore({ enabled: true, type: 'sqlite', path: resolvedDbPath }, scope)
    const memoryManager = new MemoryManager(sqliteStore)

    memoryStoreCache = {
      store: memoryManager,
      close: () => {
        sqliteStore.close()
        memoryStoreCache = null
      },
    }

    return memoryStoreCache
  } catch (error) {
    // If memory store fails to initialize, return null
    logger.error(`Failed to initialize memory store: ${error instanceof Error ? error.message : String(error)}`)
    return null
  }
}

/**
 * Schema for provider override options
 * Can be added to any tool input to allow per-call provider/model overrides
 */
const providerOverrideSchema = z.object({
  provider: z.string().optional().describe('Override the AI provider for this call (e.g., "anthropic", "deepseek", "ollama")'),
  model: z.string().optional().describe('Override the model for this call (e.g., "claude-sonnet-4-5", "deepseek-chat")'),
  parameters: z.record(z.string(), z.unknown()).optional().describe('Override model parameters for this call'),
})

/**
 * Extract provider override from tool arguments
 */
function extractProviderOverride(args: Record<string, unknown>): ProviderOverride | undefined {
  const { provider, model, parameters } = args as {
    provider?: string
    model?: string
    parameters?: Record<string, unknown>
  }

  if (provider || model || parameters) {
    return { provider, model, parameters }
  }
  return undefined
}

/**
 * Create a minimal execution context for running workflows from MCP server
 *
 * NOTE: The context must include provider configuration options for workflows to work.
 * The runWorkflow function will load the actual provider config from config files/env,
 * but it needs these context fields to be present.
 */
function createExecutionContext(_logger: Logger) {
  return {
    // Set working directory to current working directory
    cwd: process.cwd(),
    // Default to non-interactive mode for MCP
    yes: true,
    // Verbose logging - default to 0 (can be enhanced if needed)
    verbose: 0,
    // No file specified
    file: undefined,
    // Provider configuration fields (will be populated by runWorkflow from config/env)
    // These are required for runWorkflow to properly initialize the AI provider
    model: undefined as string | undefined,
    apiProvider: undefined as string | undefined,
    apiKey: undefined as string | undefined,
  }
}

/**
 * Helper to run a workflow and format the result for MCP response
 *
 * @param workflow - The workflow function to execute
 * @param input - Input parameters for the workflow
 * @param commandName - Name of the command (for config lookup)
 * @param logger - Logger instance
 * @param providerOverride - Optional provider/model override for this call
 * @param defaultProvider - Default provider config from server startup
 */
async function executeWorkflow<TInput>(
  workflow: WorkflowFn<TInput & BaseWorkflowInput, unknown, CliToolRegistry>,
  input: TInput,
  commandName: string,
  logger: Logger,
  providerOverride?: ProviderOverride,
  defaultProvider?: DefaultProviderConfig,
): Promise<string> {
  try {
    const context = createExecutionContext(logger)

    // Apply provider overrides in priority order:
    // 1. Per-call override (highest priority)
    // 2. Server default
    // 3. Leave undefined to use config file/env defaults
    const finalProvider = providerOverride?.provider || defaultProvider?.provider
    const finalModel = providerOverride?.model || defaultProvider?.model
    const finalParameters = providerOverride?.parameters || defaultProvider?.parameters
    const finalApiKey = defaultProvider?.apiKey // Only use API key from server defaults (not per-call for security)

    // Update context with overrides if provided
    if (finalProvider) {
      context.apiProvider = finalProvider
    }
    if (finalModel) {
      context.model = finalModel
    }
    if (finalApiKey) {
      context.apiKey = finalApiKey
    }

    // Add default values for BaseWorkflowInput properties
    const workflowInput = {
      ...input,
      interactive: false,
      additionalTools: {},
    } as TInput & BaseWorkflowInput

    const result = await runWorkflow(workflow, workflowInput, {
      commandName,
      context,
      logger,
      interactive: false,
      // Pass provider/model overrides to runWorkflow
      providerOverride: {
        provider: finalProvider,
        model: finalModel,
        parameters: finalParameters,
      },
    })

    if (!result) {
      // Result is undefined - this could indicate an internal error in runWorkflow
      // that was caught and not re-thrown, or a workflow that completed with no output
      // Return an error to avoid masking potential failures
      return 'Error: Workflow returned no result (possible internal error or workflow produced no output)'
    }

    // Format the result based on its structure
    if (typeof result === 'string') {
      return result
    } else if (result && typeof result === 'object') {
      // Check if it's a workflow result object
      if ('success' in result) {
        if (result.success === true) {
          // Include summary, summaries, or output if available
          const workflowResult = result as { summary?: string; summaries?: string[]; output?: string }
          return (
            workflowResult.summary || workflowResult.summaries?.join('\n') || workflowResult.output || 'Workflow completed successfully'
          )
        } else {
          // Workflow failed
          const workflowResult = result as { reason?: string; error?: string }
          return `Error: ${workflowResult.reason || workflowResult.error || 'Workflow failed'}`
        }
      }
      // Generic object - stringify it
      return JSON.stringify(result, null, 2)
    }

    return 'Workflow completed'
  } catch (error) {
    logger.error(`Error executing ${commandName} workflow:`, error)
    return `Error: ${error instanceof Error ? error.message : String(error)}`
  }
}

/**
 * Create high-level polka-codes workflow tools for MCP server
 *
 * These tools integrate with the actual polka-codes workflows to enable
 * AI assistants (via MCP) to execute code tasks, reviews, planning, etc.
 *
 * Each tool now supports optional provider/model overrides via:
 * - provider: Override the AI provider
 * - model: Override the model
 * - parameters: Override model parameters
 */
export function createPolkaCodesServerTools(logger: Logger): McpServerTool[] {
  /**
   * Escape special regex characters in a pattern for safe regex construction
   */
  function escapeRegexPattern(pattern: string): string {
    return pattern.replace(/[.+*?^${}()|[\]\\]/g, '\\$&')
  }

  /**
   * Create a regex from a wildcard pattern, supporting * and ? wildcards
   * All special regex characters except * and ? are escaped
   */
  function createWildcardRegex(pattern: string): RegExp {
    // First replace wildcards with placeholders, escape everything else, then restore wildcards
    const withWildcardsPlaceholders = pattern.replace(/\*/g, '\0STAR\0').replace(/\?/g, '\0QUEST\0')
    const escaped = escapeRegexPattern(withWildcardsPlaceholders)
    const withWildcards = escaped.replace(/\0STAR\0/g, '.*').replace(/\0QUEST\0/g, '.')
    return new RegExp(`^${withWildcards}$`)
  }

  return [
    {
      name: 'code',
      description: `Execute a coding task using AI with comprehensive codebase analysis and modification capabilities.

The workflow will:
- Analyze the current codebase structure, patterns, and dependencies
- Understand existing conventions and architectural decisions
- Make targeted code changes to accomplish the specified task
- Ensure all changes compile and pass type checking
- Run and fix any failing tests
- Handle complex multi-file changes and refactoring
- Provide a detailed summary of changes made

Best used for implementing new features, refactoring existing code, fixing bugs across multiple files, adding tests, or code modernization.

Parameters:
- task (required): Detailed description of what needs to be implemented or changed
- provider (optional): Override the AI provider for this call
- model (optional): Override the model for this call
- parameters (optional): Override model parameters for this call`,
      inputSchema: z.object({
        task: z.string().describe('The coding task to execute - be specific about what needs to be done'),
        ...providerOverrideSchema.shape,
      }),
      handler: async (args: Record<string, unknown>, toolContext: McpServerToolContext) => {
        const { task } = args as { task: string }
        const providerOverride = extractProviderOverride(args)
        logger.info(
          `MCP: Executing code workflow - task: "${task}"${providerOverride?.provider ? ` with provider: ${providerOverride.provider}` : ''}`,
        )
        return await executeWorkflow(codeWorkflow, { task }, 'code', logger, providerOverride, toolContext.defaultProvider)
      },
    },
    {
      name: 'review',
      description: `Perform comprehensive code review with actionable, structured feedback.

This workflow can review:
- Uncommitted local changes (staged and/or unstaged files) - DEFAULT BEHAVIOR when no parameters provided
- Branch comparisons (e.g., feature branch vs main)
- Specific git ranges (e.g., HEAD~3..HEAD, origin/main..HEAD)
- Pull requests from GitHub/GitLab by number

The review provides:
- Code quality and style analysis
- Bug identification and potential issues
- Security and performance concerns
- Improvement suggestions with examples
- Best practices compliance feedback
- Documentation review

Output is structured with:
- Categorized feedback (bugs, style, performance, etc.)
- Specific file/line references
- Severity levels (critical, major, minor, nitpick)
- Actionable recommendations

Parameters:
- pr (optional): Pull request number to review
- range (optional): Git range to review (e.g., HEAD~3..HEAD, origin/main..HEAD). When omitted, reviews staged and unstaged local changes
- files (optional): Specific files to review
- context (optional): Additional context about the changes (purpose, constraints, technical background)
- provider (optional): Override the AI provider for this call
- model (optional): Override the model for this call
- parameters (optional): Override model parameters for this call`,
      inputSchema: z.object({
        pr: z.number().optional().describe('Pull request number to review (optional)'),
        range: z.string().optional().describe('Git range to review (e.g., HEAD~3..HEAD, origin/main..HEAD) (optional)'),
        files: z.array(z.string()).optional().describe('Specific files to review (optional)'),
        context: z
          .string()
          .optional()
          .describe('Additional context for the review - explains the purpose of changes, constraints, or areas of focus (optional)'),
        ...providerOverrideSchema.shape,
      }),
      handler: async (args: Record<string, unknown>, toolContext: McpServerToolContext) => {
        const { pr, range, files, context } = args as { pr?: number; range?: string; files?: string[]; context?: string }
        const providerOverride = extractProviderOverride(args)
        logger.info(
          `MCP: Executing review workflow${pr ? ` - PR: ${pr}` : ''}${range ? ` - range: ${range}` : ''}${providerOverride?.provider ? ` with provider: ${providerOverride.provider}` : ''}`,
        )
        return await executeWorkflow(
          reviewWorkflow,
          { pr, range, files, context },
          'review',
          logger,
          providerOverride,
          toolContext.defaultProvider,
        )
      },
    },
    {
      name: 'plan',
      description: `Create a detailed, actionable implementation plan for features or problems.

The workflow will:
- Analyze the current codebase to understand existing architecture
- Identify key files, dependencies, and potential challenges
- Create a step-by-step implementation roadmap
- Consider edge cases, error handling, and validation
- Suggest testing strategies and test cases
- Identify potential risks and mitigation approaches
- Recommend refactoring or preparatory work if needed

The plan includes:
- Overview with recommended approach
- Ordered list of implementation steps
- Files to create or modify (file paths only, no content)
- Dependencies and prerequisites
- Testing strategy
- Risk assessment and mitigations
- Rollback strategy if applicable

Best used for complex features, architecture changes, large refactorings, or migration strategies.

Parameters:
- task (required): Detailed description of what needs to be planned
- provider (optional): Override the AI provider for this call
- model (optional): Override the model for this call
- parameters (optional): Override model parameters for this call`,
      inputSchema: z.object({
        task: z.string().describe('The task or feature to plan - provide details about requirements, constraints, and goals'),
        ...providerOverrideSchema.shape,
      }),
      handler: async (args: Record<string, unknown>, toolContext: McpServerToolContext) => {
        const { task } = args as { task: string }
        const providerOverride = extractProviderOverride(args)
        logger.info(
          `MCP: Executing plan workflow - task: "${task}"${providerOverride?.provider ? ` with provider: ${providerOverride.provider}` : ''}`,
        )

        try {
          const context = createExecutionContext(logger)

          // Apply provider overrides
          const finalProvider = providerOverride?.provider || toolContext.defaultProvider?.provider
          const finalModel = providerOverride?.model || toolContext.defaultProvider?.model
          const finalParameters = providerOverride?.parameters || toolContext.defaultProvider?.parameters
          const finalApiKey = toolContext.defaultProvider?.apiKey

          if (finalProvider) {
            context.apiProvider = finalProvider
          }
          if (finalModel) {
            context.model = finalModel
          }
          if (finalApiKey) {
            context.apiKey = finalApiKey
          }

          const result = await runWorkflow(
            planWorkflow,
            { task, interactive: false },
            {
              commandName: 'plan',
              context,
              logger,
              interactive: false,
              providerOverride: {
                provider: finalProvider,
                model: finalModel,
                parameters: finalParameters,
              },
            },
          )

          // Format plan result for MCP response
          if (result && typeof result === 'object') {
            const planResult = result as {
              plan?: string
              question?: unknown
              reason?: string
              files?: Array<{ path: string; content: string }>
            }

            // If there's a question, return it
            if (planResult.question) {
              return JSON.stringify({ question: planResult.question }, null, 2)
            }

            // If there's a reason (no plan needed), return it
            if (planResult.reason) {
              return `No plan needed: ${planResult.reason}`
            }

            // Format the plan result with file paths only (no content)
            let output = ''
            if (planResult.plan) {
              output += planResult.plan
            }

            if (planResult.files && planResult.files.length > 0) {
              output += '\n\nFiles to modify:\n'
              // Extract only the file paths, not the content
              output += planResult.files.map((f) => `  - ${f.path}`).join('\n')
            }

            return output || 'Plan created successfully'
          }

          return 'Plan created successfully'
        } catch (error) {
          logger.error(`Error executing plan workflow:`, error)
          return `Error: ${error instanceof Error ? error.message : String(error)}`
        }
      },
    },
    {
      name: 'fix',
      description: `Diagnose and resolve issues, bugs, or test failures systematically.

The workflow will:
- Analyze error messages, stack traces, and failing tests
- Identify root causes through code examination
- Review relevant code and dependencies
- Implement targeted fixes with proper error handling
- Run tests to verify the fix
- Check for regressions in related functionality
- Iterate if the issue persists

Can handle:
- Test failures (unit, integration, e2e)
- Build and compilation errors
- Type checking errors
- Runtime errors and exceptions
- Logic bugs
- Performance issues
- Security vulnerabilities

Process:
1. Thoroughly analyze the failure or error
2. Identify and understand the root cause
3. Implement a minimal, targeted fix
4. Test to verify the fix works
5. Check for regressions
6. Iterate if needed until resolved

Parameters:
- task (required): Description of the issue - include error messages, stack traces, or describe what's not working
- provider (optional): Override the AI provider for this call
- model (optional): Override the model for this call
- parameters (optional): Override model parameters for this call`,
      inputSchema: z.object({
        task: z.string().describe("Description of the issue to fix - include error messages, stack traces, or describe what's not working"),
        ...providerOverrideSchema.shape,
      }),
      handler: async (args: Record<string, unknown>, toolContext: McpServerToolContext) => {
        const { task } = args as { task: string }
        const providerOverride = extractProviderOverride(args)
        logger.info(
          `MCP: Executing fix workflow - task: "${task}"${providerOverride?.provider ? ` with provider: ${providerOverride.provider}` : ''}`,
        )
        return await executeWorkflow(fixWorkflow, { task }, 'fix', logger, providerOverride, toolContext.defaultProvider)
      },
    },
    {
      name: 'commit',
      description: `Create a git commit with an AI-generated, well-formatted commit message.

The workflow will:
- Stage specified files (all files or specific files)
- Analyze the diff to understand what changed
- Generate a clear, descriptive commit message following best practices
- Create the commit with the generated message

Commit message format:
- Clear subject line (50 chars or less)
- Detailed body explaining what changed and why
- References to issues/PRs if applicable
- Conventional commits format when appropriate

Best practices followed:
- Separate subject from body with blank line
- Use imperative mood in subject line (e.g., "Add feature" not "Added feature")
- Explain what and why, not how
- Wrap body lines at 72 characters

Parameters:
- message (optional): Custom commit message. If not provided, AI analyzes changes and generates an appropriate message following best practices
- stageFiles (optional): Files to stage before committing. Use "all" to stage all files, or provide an array of specific file paths to stage
- provider (optional): Override the AI provider for this call
- model (optional): Override the model for this call
- parameters (optional): Override model parameters for this call`,
      inputSchema: z.object({
        message: z
          .string()
          .optional()
          .describe('Optional commit message - if not provided, AI will analyze changes and generate an appropriate message'),
        stageFiles: z
          .union([z.literal('all'), z.array(z.string())])
          .optional()
          .describe('Files to stage: "all" for all files, or array of specific file paths'),
        ...providerOverrideSchema.shape,
      }),
      handler: async (args: Record<string, unknown>, toolContext: McpServerToolContext) => {
        const { message, stageFiles } = args as { message?: string; stageFiles?: 'all' | string[] }
        const providerOverride = extractProviderOverride(args)
        logger.info(
          `MCP: Executing commit workflow${message ? ` - message: "${message}"` : ''}${stageFiles ? ` - stageFiles: "${JSON.stringify(stageFiles)}"` : ''}${providerOverride?.provider ? ` with provider: ${providerOverride.provider}` : ''}`,
        )
        try {
          // Apply provider overrides for commit
          const context = createExecutionContext(logger)
          const finalProvider = providerOverride?.provider || toolContext.defaultProvider?.provider
          const finalModel = providerOverride?.model || toolContext.defaultProvider?.model
          const finalApiKey = toolContext.defaultProvider?.apiKey

          if (finalProvider) {
            context.apiProvider = finalProvider
          }
          if (finalModel) {
            context.model = finalModel
          }
          if (finalApiKey) {
            context.apiKey = finalApiKey
          }

          const commitMessage = await commit({
            ...context,
            context: message,
            all: stageFiles === 'all',
            files: Array.isArray(stageFiles) ? stageFiles : undefined,
            interactive: false,
          })
          return commitMessage || 'Commit created successfully'
        } catch (error) {
          return `Error: ${error instanceof Error ? error.message : String(error)}`
        }
      },
    },
    {
      name: 'memory_read',
      description: `Read content from a memory topic.

Use this to retrieve information stored in previous workflow steps.
Memory persists across tool calls, allowing you to maintain context
between different operations.

Parameters:
- topic (optional): The memory topic to read from. Defaults to ":default:" which stores general conversation context.

Returns the content stored in the specified topic, or a message indicating the topic is empty.`,
      inputSchema: z.object({
        topic: z.string().optional().describe('The memory topic to read from (defaults to ":default:")'),
      }),
      handler: async (args: Record<string, unknown>, toolContext: McpServerToolContext) => {
        const { topic = ':default:' } = args as { topic?: string }
        toolContext.logger.info(`MCP: Reading from memory topic "${topic}"`)

        const memoryStore = await getMemoryStore(toolContext.logger)
        if (!memoryStore) {
          return 'Error: Memory store is not enabled. Configure it in your .polkacodes.yml with memory.enabled: true'
        }

        try {
          const content = await memoryStore.store.readMemory(topic)
          if (content) {
            return content
          }
          return `Memory topic "${topic}" is empty.`
        } catch (error) {
          return `Error: ${error instanceof Error ? error.message : String(error)}`
        }
      },
    },
    {
      name: 'memory_update',
      description: `Update content in a memory topic.

Use this to store information for later retrieval in subsequent tool calls.
Memory persists across tool calls, allowing you to maintain context
between different operations.

Parameters:
- operation (required): The operation to perform. Use "append" to add content, "replace" to overwrite all content, or "remove" to delete the topic.
- topics (optional): Array of topic names for batch operations. Content can be an array (one per topic) or a single string (broadcast to all topics).
- topic (optional): Single memory topic to update. Defaults to ":default:".
- content (optional): The content to store (required for "append" and "replace" operations). For batch operations with topics, provide an array of the same length or a single string to broadcast.

Supports wildcards in topic name for remove operation:
- Use "*" to remove all topics (e.g., topic ":plan:*")
- Use pattern matching like ":plan:*" to remove all topics starting with ":plan:"

Returns a message confirming the operation performed.`,
      inputSchema: z
        .object({
          operation: z
            .enum(['append', 'replace', 'remove'])
            .describe('The operation: append (add content), replace (overwrite), or remove (delete topic(s))'),
          topic: z.string().optional().describe('Single memory topic to update (defaults to ":default:")'),
          topics: z.array(z.string()).min(1).optional().describe('Array of topics for batch operations'),
          content: z
            .union([z.string(), z.array(z.string())])
            .optional()
            .describe('Content to store (string or array for batch). Required for append/replace, omitted for remove'),
        })
        .refine(
          (data) => {
            // If topics array is provided with content, validate the combination
            if (data.topics && data.content) {
              // Array content must match topics length
              if (Array.isArray(data.content)) {
                return data.content.length === data.topics.length
              }
              // String content can be broadcast to any number of topics
              return true
            }
            // If topics is not provided (single topic mode), content must be a string or undefined
            if (!data.topics && data.content !== undefined && Array.isArray(data.content)) {
              return false
            }
            return true
          },
          {
            message:
              'For single topic mode, content must be a string. For batch mode with topics array, content can be an array (same length) or a string (broadcast to all topics)',
          },
        ),
      handler: async (args: Record<string, unknown>, toolContext: McpServerToolContext) => {
        const {
          operation,
          topic: singleTopic,
          topics,
          content: contentInput,
        } = args as {
          operation: 'append' | 'replace' | 'remove'
          topic?: string
          topics?: string[]
          content?: string | string[]
        }
        toolContext.logger.info(`MCP: Memory operation "${operation}" on ${topics ? `${topics.length} topics` : `topic "${singleTopic}"`}`)

        const memoryStore = await getMemoryStore(toolContext.logger)
        if (!memoryStore) {
          return 'Error: Memory store is not enabled. Configure it in your .polkacodes.yml with memory.enabled: true'
        }

        try {
          // Handle batch operations
          if (topics) {
            // Validate content requirement for batch
            if (operation === 'remove' && contentInput !== undefined) {
              return 'Error: Content must not be provided for "remove" operation'
            }
            if ((operation === 'append' || operation === 'replace') && contentInput === undefined) {
              return 'Error: Content is required for "append" and "replace" operations'
            }

            const contents = Array.isArray(contentInput) ? contentInput : topics.map(() => contentInput as string)

            // Build batch operations
            const operations = topics.map((topic, index) => ({
              operation,
              name: topic,
              content: operation === 'remove' ? undefined : contents[index],
            }))

            await memoryStore.store.batchUpdateMemory(operations)
            return `Batch operation "${operation}" completed on ${topics.length} topics:\n${topics.join('\n')}`
          }

          // Handle wildcard removal
          const topic = singleTopic || ':default:'
          if (operation === 'remove' && (topic.includes('*') || topic.includes('?'))) {
            // Query all entries and filter by wildcard pattern
            const allEntries = await memoryStore.store.queryMemory({ scope: 'auto' }, { operation: 'select' })
            if (!Array.isArray(allEntries)) {
              return 'Error: Unable to query memory entries'
            }

            const regex = createWildcardRegex(topic)

            const matchingTopics = allEntries.filter((e) => regex.test(e.name)).map((e) => e.name)

            if (matchingTopics.length === 0) {
              return `No topics found matching pattern "${topic}"`
            }

            // Batch remove all matching topics
            const operations = matchingTopics.map((matchingTopic) => ({
              operation: 'remove' as const,
              name: matchingTopic,
            }))

            await memoryStore.store.batchUpdateMemory(operations)
            return `Removed ${matchingTopics.length} topic(s) matching pattern "${topic}":\n${matchingTopics.join('\n')}`
          }

          // Handle single topic operation
          if ((operation === 'append' || operation === 'replace') && contentInput === undefined) {
            return 'Error: Content is required for "append" and "replace" operations'
          }
          if (operation === 'remove' && contentInput !== undefined) {
            return 'Error: Content must not be provided for "remove" operation'
          }

          const content = typeof contentInput === 'string' ? contentInput : undefined
          await memoryStore.store.updateMemory(operation, topic, content)

          const messages = {
            append: `Content appended to memory topic "${topic}"`,
            replace: `Memory topic "${topic}" replaced`,
            remove: `Memory topic "${topic}" removed`,
          }

          return messages[operation]
        } catch (error) {
          return `Error: ${error instanceof Error ? error.message : String(error)}`
        }
      },
    },
    {
      name: 'memory_list',
      description: `List all available memory topics.

Use this to see what information has been stored and which topics are
available to read from. Returns a list of topic names that have content.

Parameters:
- pattern (optional): Filter topics by wildcard pattern (e.g., ":plan:*" for all plan topics)
- scope (optional): Filter by scope ("auto", "project", or "global")`,
      inputSchema: z.object({
        pattern: z.string().optional().describe('Filter topics by wildcard pattern (e.g., ":plan:*")'),
        scope: z.enum(['auto', 'project', 'global']).optional().describe('Filter by scope (defaults to "auto")'),
      }),
      handler: async (args: Record<string, unknown>, toolContext: McpServerToolContext) => {
        const { pattern, scope } = args as { pattern?: string; scope?: 'auto' | 'project' | 'global' }
        toolContext.logger.info(`MCP: Listing memory topics${pattern ? ` with pattern "${pattern}"` : ''}`)

        const memoryStore = await getMemoryStore(toolContext.logger)
        if (!memoryStore) {
          return 'Error: Memory store is not enabled. Configure it in your .polkacodes.yml with memory.enabled: true'
        }

        try {
          // Query memory entries with filters
          const query: { scope?: 'global' | 'project' | 'auto' } = {}
          query.scope = scope ?? 'auto'

          const entries = await memoryStore.store.queryMemory(query, { operation: 'select' })
          if (!entries || !Array.isArray(entries) || entries.length === 0) {
            return 'No memory topics found.'
          }

          // Extract topic names and filter by pattern if provided
          let topics = [...new Set(entries.map((e) => e.name))]
          if (pattern) {
            const regex = createWildcardRegex(pattern)
            topics = topics.filter((t) => regex.test(t))
          }

          if (topics.length === 0) {
            return pattern ? `No memory topics found matching pattern "${pattern}"` : 'No memory topics found.'
          }

          return `Memory topics (${topics.length}):\n${topics.join('\n')}`
        } catch (error) {
          return `Error: ${error instanceof Error ? error.message : String(error)}`
        }
      },
    },
    {
      name: 'memory_query',
      description: `Query memory with advanced filters.

Use this to search memory entries by content, metadata, or other criteria.
Returns detailed entry information with metadata.

Parameters:
- search (optional): Search text to find in content
- type (optional): Filter by entry type (note, todo, plan, etc.)
- status (optional): Filter by status (open, completed, closed, etc.)
- priority (optional): Filter by priority (null, low, medium, high)
- tags (optional): Filter by tags
- scope (optional): Filter by scope ("auto", "project", or "global")
- operation (optional): Query operation - "select" returns entries, "count" returns count

Returns matching entries with full metadata.`,
      inputSchema: z.object({
        search: z.string().optional().describe('Search text to find in content'),
        type: z.string().optional().describe('Filter by entry type (note, todo, plan, etc.)'),
        status: z.string().optional().describe('Filter by status (open, completed, closed, etc.)'),
        priority: z.string().optional().describe('Filter by priority (null, low, medium, high)'),
        tags: z.string().optional().describe('Filter by tags'),
        scope: z.enum(['auto', 'project', 'global']).optional().describe('Filter by scope (defaults to "auto")'),
        operation: z.enum(['select', 'count']).optional().describe('Query operation (defaults to "select")'),
      }),
      handler: async (args: Record<string, unknown>, toolContext: McpServerToolContext) => {
        const {
          search,
          type,
          status,
          priority,
          tags,
          scope,
          operation = 'select',
        } = args as {
          search?: string
          type?: string
          status?: string
          priority?: string
          tags?: string
          scope?: 'auto' | 'project' | 'global'
          operation?: 'select' | 'count'
        }
        toolContext.logger.info(`MCP: Querying memory - operation: "${operation}"`)

        const memoryStore = await getMemoryStore(toolContext.logger)
        if (!memoryStore) {
          return 'Error: Memory store is not enabled. Configure it in your .polkacodes.yml with memory.enabled: true'
        }

        try {
          // Build query object
          const memoryQuery: {
            scope?: 'global' | 'project' | 'auto'
            search?: string
            type?: string
            status?: string
            priority?: string
            tags?: string
          } = {}

          memoryQuery.scope = scope ?? 'auto'
          if (search) memoryQuery.search = search
          if (type) memoryQuery.type = type
          if (status) memoryQuery.status = status
          if (priority) memoryQuery.priority = priority
          if (tags) memoryQuery.tags = tags

          const result = await memoryStore.store.queryMemory(memoryQuery, { operation })

          if (operation === 'count') {
            return `Found ${typeof result === 'number' ? result : 0} matching entries`
          }

          // Format entries for display
          if (!Array.isArray(result) || result.length === 0) {
            return 'No matching entries found.'
          }

          const formatted = result.map((entry) => {
            const lines: string[] = []
            lines.push(`Topic: ${entry.name}`)
            if (entry.entry_type) lines.push(`  Type: ${entry.entry_type}`)
            if (entry.status) lines.push(`  Status: ${entry.status}`)
            if (entry.priority) lines.push(`  Priority: ${entry.priority}`)
            if (entry.tags) lines.push(`  Tags: ${entry.tags}`)
            if (entry.created_at) lines.push(`  Created: ${new Date(entry.created_at).toISOString()}`)
            lines.push(`  Content: ${entry.content?.substring(0, 100)}${entry.content && entry.content.length > 100 ? '...' : ''}`)
            return lines.join('\n')
          })

          return `Found ${result.length} entries:\n\n${formatted.join('\n\n')}`
        } catch (error) {
          return `Error: ${error instanceof Error ? error.message : String(error)}`
        }
      },
    },
  ]
}
