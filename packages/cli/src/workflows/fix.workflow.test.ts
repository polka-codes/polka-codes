// generated by polka.codes

import { afterEach, describe, expect, mock, spyOn, test } from 'bun:test'
import * as cliShared from '@polka-codes/cli-shared'
import type { WorkflowContext } from '@polka-codes/workflow'
import type { CliToolRegistry } from '../workflow-tools'
import { fixWorkflow } from './fix.workflow'
import * as prompts from './prompts'

const createMockContext = () => {
  const tools = {
    executeCommand: mock<any>(),
    input: mock<any>(),
    generateText: mock<any>(),
    taskEvent: mock<any>(),
    getMemoryContext: mock<any>(async () => ''),
    updateMemory: mock<any>(),
    // Add other tool mocks if needed by the workflow
  }
  const step = mock(async (_name: string, fn: () => any) => fn())
  const logger = {
    info: mock(() => {}),
    error: mock(() => {}),
    warn: mock(() => {}),
    debug: mock(() => {}),
  }

  const context = {
    tools,
    step,
    logger,
  } as unknown as WorkflowContext<CliToolRegistry>

  return { context, tools, step, logger }
}

describe('fixWorkflow', () => {
  afterEach(() => {
    mock.restore()
  })

  test('should succeed when command passes on first attempt', async () => {
    const { context, tools } = createMockContext()
    tools.executeCommand.mockResolvedValue({ exitCode: 0, stdout: 'All tests passed', stderr: '' })

    const result = await fixWorkflow({ command: 'bun test' }, context)

    expect(tools.executeCommand).toHaveBeenCalledWith({ command: 'bun test', shell: true, pipe: true })
    expect(result).toStrictEqual({ success: true, summaries: [] })
  })

  test('should prompt for command when not provided', async () => {
    const { context, tools } = createMockContext()
    const loadConfigSpy = spyOn(cliShared, 'loadConfig').mockReturnValue({
      scripts: {
        check: 'bun typecheck',
        test: 'bun test',
      },
    })

    tools.input.mockResolvedValue('bun typecheck && bun test')
    tools.executeCommand.mockResolvedValue({ exitCode: 0, stdout: 'Success', stderr: '' })

    await fixWorkflow({ interactive: true }, context)

    expect(tools.input).toHaveBeenCalledWith({
      message: 'Please enter the command to run to identify issues:',
      default: 'bun typecheck && bun test',
    })
    expect(tools.executeCommand).toHaveBeenCalledWith({
      command: 'bun typecheck && bun test',
      shell: true,
      pipe: true,
    })

    loadConfigSpy.mockRestore()
  })

  test('should use default command when not interactive', async () => {
    const { context, tools } = createMockContext()
    const loadConfigSpy = spyOn(cliShared, 'loadConfig').mockReturnValue({
      scripts: {
        check: 'bun typecheck',
      },
    })

    tools.executeCommand.mockResolvedValue({ exitCode: 0, stdout: '', stderr: '' })

    await fixWorkflow({ interactive: false }, context)

    expect(tools.executeCommand).toHaveBeenCalledWith({ command: 'bun typecheck', shell: true, pipe: true })

    loadConfigSpy.mockRestore()
  })

  test('should throw error when no command provided and user provides empty input', async () => {
    const { context, tools } = createMockContext()
    const loadConfigSpy = spyOn(cliShared, 'loadConfig').mockReturnValue({})
    tools.input.mockResolvedValue('')

    const promise = fixWorkflow({ interactive: true }, context)

    await expect(promise).rejects.toThrow('No command provided. Aborting.')
    loadConfigSpy.mockRestore()
  })

  test('should succeed after agent fixes the issue', async () => {
    const { context, tools } = createMockContext()

    tools.executeCommand
      .mockResolvedValueOnce({ exitCode: 1, stdout: 'FAIL', stderr: 'Error' })
      .mockResolvedValueOnce({ exitCode: 0, stdout: 'PASS', stderr: '' })

    tools.generateText.mockResolvedValue([
      {
        role: 'assistant',
        content: '```json\n{"summary":"I did a fix","bailReason":null}\n```',
      },
    ])

    const result = await fixWorkflow({ command: 'bun test' }, context)

    expect(tools.executeCommand).toHaveBeenCalledTimes(2)
    expect(tools.generateText).toHaveBeenCalledTimes(1)
    expect(result).toStrictEqual({ success: true, summaries: ['I did a fix'] })
  })

  test('should fail after exhausting all retries', async () => {
    const { context, tools } = createMockContext()

    tools.executeCommand.mockResolvedValue({ exitCode: 1, stdout: 'FAIL', stderr: 'Error' })
    tools.generateText.mockResolvedValue([
      {
        role: 'assistant',
        content: '```json\n{"summary":"I did a fix","bailReason":null}\n```',
      },
    ])

    const result = await fixWorkflow({ command: 'bun test' }, context)

    expect(tools.executeCommand).toHaveBeenCalledTimes(10)
    expect(tools.generateText).toHaveBeenCalledTimes(10)
    expect(result).toStrictEqual({
      success: false,
      reason: 'Failed to fix the issue after maximum attempts.',
      summaries: [
        'I did a fix',
        'I did a fix',
        'I did a fix',
        'I did a fix',
        'I did a fix',
        'I did a fix',
        'I did a fix',
        'I did a fix',
        'I did a fix',
        'I did a fix',
      ],
    })
  })

  test('should return bailReason when agent cannot fix', async () => {
    const { context, tools } = createMockContext()

    tools.executeCommand.mockResolvedValue({ exitCode: 1, stdout: 'FAIL', stderr: 'Mysterious error' })
    tools.generateText.mockResolvedValue([
      {
        role: 'assistant',
        content: '```json\n{"summary":null,"bailReason":"Unable to identify the root cause of the error"}\n```',
      },
    ])

    const result = await fixWorkflow({ command: 'bun test' }, context)

    expect(tools.executeCommand).toHaveBeenCalledTimes(1)
    expect(tools.generateText).toHaveBeenCalledTimes(1)
    expect(result).toStrictEqual({
      success: false,
      summaries: [],
      reason: 'Unable to identify the root cause of the error',
    })
  })

  test('should pass task to agent prompt', async () => {
    const { context, tools } = createMockContext()
    const getFixUserPromptSpy = spyOn(prompts, 'getFixUserPrompt')

    tools.executeCommand.mockResolvedValue({
      exitCode: 1,
      stdout: 'FAIL src/test.ts',
      stderr: 'TypeError: undefined is not a function',
    })
    tools.generateText.mockResolvedValue([
      {
        role: 'assistant',
        content: '```json\n{"summary":"I did a fix"}\n```',
      },
    ])

    tools.generateText.mockResolvedValue([
      {
        role: 'assistant',
        content: '```json\n{"summary":"I did a fix","bailReason":null}\n```',
      },
    ])

    tools.executeCommand
      .mockResolvedValueOnce({ exitCode: 1, stdout: 'FAIL', stderr: 'Error' })
      .mockResolvedValueOnce({ exitCode: 0, stdout: 'PASS', stderr: '' })

    await fixWorkflow({ command: 'bun test', task: 'My original task was to do this thing.' }, context)

    expect(getFixUserPromptSpy).toHaveBeenCalledTimes(1)
    expect(tools.generateText).toHaveBeenCalledTimes(1)

    const generateTextCall = tools.generateText.mock.calls[0][0] as { messages: { role: string; content: string }[] }
    const userMessage = generateTextCall.messages.find((m: { role: string }) => m.role === 'user')
    expect(userMessage?.content).toContain('My original task was to do this thing.')

    getFixUserPromptSpy.mockRestore()
  })
})
